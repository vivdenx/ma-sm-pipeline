{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notebook for simple text classification\n",
    "\n",
    "This notebooks contains code for simple classification of tweets into 'offensive' ('OFF') and non-offensive ('NOT'). \n",
    "\n",
    "You can use **simple vocabulary-counts as features** by calling:\n",
    "\n",
    "\n",
    "`path_to_data = 'path/to/your/offenseval_data/` (e.g. '../../../../../Data/offenseval/offenseval2017/')\n",
    "\n",
    "`classify_count(path_to_data)`\n",
    "\n",
    "Or you can use **embeddings as features** by calling:\n",
    "\n",
    "`path_to_model = path/to/embedding_model.bin' (e.g. ../../../../../Data/dsm/word2vec/GoogleNews-vectors-negative300.bin')`\n",
    "\n",
    "`path_to_data = 'path/to/your/offenseval_data/` (e.g. '../../../../../Data/offenseval/offenseval2017/')\n",
    "\n",
    "`model_name = 'google_news'` (give your model a name)\n",
    "\n",
    "`classify_embeddings(path_to_data, path_to_model, model_name)`\n",
    "\n",
    "The resulting predictions will be stored in the directory ./predictions/ and the performance (f1, recall, precision) will be printed to the screen. \n",
    "\n",
    "Note that you have to run all the cells in the notebook before you can call the functions as shown above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions\n",
    "\n",
    "Run these cells.\n",
    "\n",
    "(Feel free to modify the code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(data_dir, setname):\n",
    "    test_path = 'offenseval-trial.txt'\n",
    "    train_path = 'offenseval-training-v1.tsv'\n",
    "    if setname == 'test':\n",
    "        filepath = data_dir+test_path\n",
    "        data = pd.read_csv(filepath, \n",
    "                       delimiter = '\\t', \n",
    "                       header = None,  \n",
    "                       names=[\"tweet\", \"subtask_a\", \"subtask_b\", \"subtask_c\"])\n",
    "    elif setname == 'train':\n",
    "        filepath = data_dir+train_path\n",
    "        data = pd.read_csv(filepath, delimiter=\"\\t\")  \n",
    "    return data\n",
    "\n",
    "def split_train(train_data):\n",
    "    # split 90%, 10%\n",
    "    total = len(train_data)\n",
    "    total_90 = round(total * 0.9)\n",
    "    train_data_split = train_data[:total_90]\n",
    "    validation_data = train_data[total_90:]\n",
    "    return train_data_split, validation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "from nltk import TweetTokenizer\n",
    "import string \n",
    "# tokenize, remove stop-words\n",
    "\n",
    "def tokenize(data, remove_stop_words = True):\n",
    "    tokenized_tweets = []\n",
    "    tokenizer = TweetTokenizer()\n",
    "    to_remove = list(string.punctuation)\n",
    "    to_remove.extend(['@USER', 'URL'])\n",
    "    for tweet in data['tweet']:\n",
    "        tokenized_tweet = ' '.join(tokenizer.tokenize(tweet))\n",
    "        if remove_stop_words == True:\n",
    "            for char in to_remove:\n",
    "                tokenized_tweet = tokenized_tweet.replace(char.strip(), '').lower()\n",
    "        tokenized_tweets.append(tokenized_tweet)\n",
    "    data['tweet_tok'] = tokenized_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform preprocessed tweets to vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainsform tweets to vocab count vectors \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def tweets_to_count_vec(tweets_train, tweets_test):\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_X = vectorizer.fit_transform(tweets_train)\n",
    "    test_X = vectorizer.transform(tweets_test)\n",
    "    return train_X, test_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to embedding vecs (assuming gensim compatible model)\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "def tweets_to_embedding(tweets, model_path):\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, binary = True)\n",
    "    data_X = []\n",
    "    for tweet in tweets:\n",
    "        #tweet was tokenized and joined by ' ' in the previous step\n",
    "        tokens = tweet.split(' ')\n",
    "        tweet_vecs = np.array([model[t] for t in tokens if t in model.vocab])\n",
    "        if len(tweet_vecs) > 1:\n",
    "            average_embedding = np.mean(tweet_vecs, axis = 0)\n",
    "        else:\n",
    "            n_d = len(model['the'])\n",
    "            average_embedding = np.zeros(n_d)\n",
    "        data_X.append(average_embedding)\n",
    "    return np.array(data_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify tweets using an SVM binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify\n",
    "from sklearn import svm\n",
    "\n",
    "def train(train_X, train_y):\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf.fit(train_X, train_y)  \n",
    "    return clf\n",
    "\n",
    "def predict(clf, test_X):\n",
    "    predictions = clf.predict(test_X)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write predictions to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output to file for further analysis\n",
    "import os \n",
    "import csv\n",
    "\n",
    "def predictions_to_file(tweets, gold, predictions, name):\n",
    "    \n",
    "    if not os.path.isdir('predictions/'):\n",
    "        os.mkdir('predictions/')\n",
    "    results_dict_list = []\n",
    "    \n",
    "    for tweet, gl, pl in zip(tweets, gold, predictions):\n",
    "        results_dict = dict()\n",
    "        results_dict['tweet'] = tweet\n",
    "        results_dict['gold_label'] = gl\n",
    "        results_dict['predicted_label'] = pl\n",
    "        results_dict_list.append(results_dict)\n",
    "    \n",
    "    with open(f'predictions/{name}.csv', 'w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames = results_dict_list[0].keys())\n",
    "        writer.writeheader()\n",
    "        for d in results_dict_list:\n",
    "            writer.writerow(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate using precision, recall and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(gold, predictions):\n",
    "    class_report = classification_report(gold, predictions, labels = ['OFF', 'NOT'])\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_count(path_to_data):\n",
    "    \n",
    "    train_data = load_data(data_dir, 'train')\n",
    "    test_data = load_data(data_dir, 'test')\n",
    "    train_data, val_data = split_train(train_data)\n",
    "    \n",
    "    tokenize(train_data, remove_stop_words = True)\n",
    "    tokenize(test_data, remove_stop_words = True)\n",
    "    tokenize(val_data, remove_stop_words = True)\n",
    "    \n",
    "    train_X, val_X = tweets_to_count_vec(train_data['tweet_tok'], val_data['tweet_tok']) \n",
    "    train_X, test_X = tweets_to_count_vec(train_data['tweet_tok'], test_data['tweet_tok'])\n",
    "    \n",
    "    train_y = train_data['subtask_a']\n",
    "    \n",
    "    clf = train(train_X, train_y)\n",
    "    predictions_val = predict(clf, val_X)  \n",
    "    predictions_test = predict(clf, test_X)\n",
    "    \n",
    "    name_val = 'count_svm_val'\n",
    "    predictions_to_file(val_data['tweet'], val_data['subtask_a'], predictions_val, name_val)\n",
    "    name_test = 'count_svm_test'\n",
    "    predictions_to_file(test_data['tweet'], test_data['subtask_a'], predictions_test, name_test)\n",
    "    \n",
    "    print('--- performance on the validation set')\n",
    "    evaluate(val_data['subtask_a'], predictions_val)\n",
    "    print('--- performance on the test set')\n",
    "    evaluate(test_data['subtask_a'], predictions_test)\n",
    "    \n",
    "    print(f'valdidation predictions written to: predictions/{name_val}.csv')\n",
    "    print(f'test predictions written to: predictions/{name_test}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_embeddings(path_to_data, path_to_model, model_name):\n",
    "    \n",
    "    train_data = load_data(data_dir, 'train')\n",
    "    test_data = load_data(data_dir, 'test')\n",
    "    train_data, val_data = split_train(train_data)\n",
    "    \n",
    "    tokenize(train_data, remove_stop_words = True)\n",
    "    tokenize(test_data, remove_stop_words = True)\n",
    "    tokenize(val_data, remove_stop_words = True)\n",
    "    \n",
    "    train_X = tweets_to_embedding(train_data['tweet_tok'], path_to_model) \n",
    "    val_X = tweets_to_embedding(val_data['tweet_tok'], path_to_model)   \n",
    "    test_X = tweets_to_embedding(test_data['tweet_tok'], path_to_model) \n",
    "    \n",
    "    train_y = train_data['subtask_a']\n",
    "    \n",
    "    clf = train(train_X, train_y)\n",
    "    predictions_val = predict(clf, val_X)\n",
    "    predictions_test = predict(clf, test_X)\n",
    "    \n",
    "    name_val = f'embeddings-{model_name}_svm_val'\n",
    "    predictions_to_file(val_data['tweet'], val_data['subtask_a'], predictions_val, name_val)\n",
    "    name_test = f'embeddings-{model_name}_svm_test'\n",
    "    predictions_to_file(test_data['tweet'], test_data['subtask_a'], predictions_test, name_test)\n",
    "    \n",
    "    print('--- performance on the validation set')\n",
    "    evaluate(val_data['subtask_a'], predictions_val)\n",
    "    print('--- performance on the test set')\n",
    "    evaluate(test_data['subtask_a'], predictions_test)\n",
    "    \n",
    "    print(f'valdidation predictions written to: predictions/{name_val}.csv')\n",
    "    print(f'test predictions written to: predictions/{name_test}.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your experiments here\n",
    "\n",
    "Examples are given below. Note that you have to make sure the data are stored on your computer and that you have to modify the filepaths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- performance on the validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OFF       0.89      0.25      0.39       440\n",
      "         NOT       0.73      0.98      0.84       884\n",
      "\n",
      "    accuracy                           0.74      1324\n",
      "   macro avg       0.81      0.62      0.61      1324\n",
      "weighted avg       0.78      0.74      0.69      1324\n",
      "\n",
      "--- performance on the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OFF       0.85      0.44      0.58        77\n",
      "         NOT       0.85      0.98      0.91       243\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.85      0.71      0.74       320\n",
      "weighted avg       0.85      0.85      0.83       320\n",
      "\n",
      "valdidation predictions written to: predictions/count_svm_val.csv\n",
      "test predictions written to: predictions/count_svm_test.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = '../../../../../Data/offenseval/offenseval2017/'\n",
    "classify_count(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/anaconda/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/anaconda/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- performance on the validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OFF       0.76      0.51      0.61       440\n",
      "         NOT       0.79      0.92      0.85       884\n",
      "\n",
      "    accuracy                           0.78      1324\n",
      "   macro avg       0.77      0.72      0.73      1324\n",
      "weighted avg       0.78      0.78      0.77      1324\n",
      "\n",
      "--- performance on the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OFF       0.65      0.66      0.66        77\n",
      "         NOT       0.89      0.89      0.89       243\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.77      0.78      0.77       320\n",
      "weighted avg       0.84      0.83      0.83       320\n",
      "\n",
      "valdidation predictions written to: predictions/embeddings-google_news_svm_val.csv\n",
      "test predictions written to: predictions/embeddings-google_news_svm_test.csv\n"
     ]
    }
   ],
   "source": [
    "path_to_model = '../../../../../Data/dsm/word2vec/GoogleNews-vectors-negative300.bin' \n",
    "data_dir = '../../../../../Data/offenseval/offenseval2017/'\n",
    "model_name = 'google_news'\n",
    "\n",
    "classify_embeddings(data_dir, path_to_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
